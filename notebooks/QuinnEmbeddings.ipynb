{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../run'))\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from abc import abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 33\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StimulusGenerator\n",
    "\n",
    "Abstract class that describes what we want out of a generator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CANVAS_SIZE = (224, 224)\n",
    "\n",
    "NORMALIZE = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "class StimulusGenerator:\n",
    "    def __init__(self, dtype):\n",
    "        self.dtype = dtype\n",
    "    \n",
    "    @abstractmethod\n",
    "    def generate(self, target_position, reference_positions) -> torch.Tensor:\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, target_position, reference_positions) -> torch.Tensor:\n",
    "        return NORMALIZE(self.generate(target_position, reference_positions))\n",
    "        \n",
    "    def batch_generate(self, target_positions, reference_positions) -> torch.Tensor:\n",
    "        if len(reference_positions) != len(target_positions):\n",
    "            reference_positions = [reference_positions] * len(target_positions)\n",
    "        return torch.stack([NORMALIZE(self.generate(t, p)) for (t, p) in zip(target_positions, reference_positions)])\n",
    "    \n",
    "    def _to_tensor(self, t):\n",
    "        return torch.tensor(t, dtype=self.dtype)\n",
    "    \n",
    "    def _validate_input_to_tuple(self, input_value, n_args=2):\n",
    "        if not hasattr(input_value, '__len__') or len(input_value) == 1:\n",
    "            return (input_value, ) * n_args\n",
    "        \n",
    "        return input_value\n",
    "    \n",
    "\n",
    "class NaiveStimulusGenerator(StimulusGenerator):\n",
    "    def _validate_color_input(self, c):\n",
    "        if isinstance(c, str):\n",
    "            t = self._to_tensor(colors.to_rgb(c))\n",
    "        else:\n",
    "            t = self.to_tensor(self._validate_input_to_tuple(c, 3))\n",
    "        \n",
    "        return t.view(3, 1, 1)\n",
    "    \n",
    "    def __init__(self, target_size, reference_size, canvas_size=DEFAULT_CANVAS_SIZE,\n",
    "                 target_color='red', reference_color='blue', background_color='white',\n",
    "                 dtype=torch.float64):\n",
    "        super(NaiveStimulusGenerator, self).__init__(dtype)\n",
    "        \n",
    "        self.target_size = self._validate_input_to_tuple(target_size)\n",
    "        self.reference_size = self._validate_input_to_tuple(reference_size)\n",
    "        self.canvas_size = self._validate_input_to_tuple(canvas_size)\n",
    "        \n",
    "        self.target_color = self._validate_color_input(target_color)\n",
    "        self.reference_color = self._validate_color_input(reference_color)\n",
    "        self.background_color = self._validate_color_input(background_color)\n",
    "        \n",
    "    def generate(self, target_position, reference_positions) -> torch.Tensor:\n",
    "        x = torch.ones(3, *self.canvas_size, dtype=self.dtype) * self.background_color\n",
    "        x[:, target_position[0]:target_position[0] + self.target_size[0],\n",
    "             target_position[1]:target_position[1] + self.target_size[1]] = self.target_color\n",
    "        \n",
    "        for ref_pos in reference_positions:\n",
    "            x[:, ref_pos[0]:ref_pos[0] + self.reference_size[0],\n",
    "                 ref_pos[1]:ref_pos[1] + self.reference_size[1]] = self.reference_color\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAO5klEQVR4nO3dbYwd5XnG8f9V8/IBqGzHrmX5pWsjJ5JTtYu7opYCKC1NAlaVhX4gtipwUlSDZEugpqoMSC3qpzSNQUJtHRlhxVTEQGso/uC0OBYKilQT1sQxfsF47diyV8vaIRWgECWxfffDPBuG9W72+MyZnbN9rp90dGaembPnPhr70syco+dWRGBm+fqtpgsws2Y5BMwy5xAwy5xDwCxzDgGzzDkEzDJXWwhIuk3SUUmDkjbW9T5mVo3q+J2ApBnA28DngDPA68CaiDjc8Tczs0rqOhO4ERiMiBMR8UvgWaC/pvcyswquqOnvLgBOl9bPAH800c5z5syJnp6emkoxM4B9+/b9JCLmjh2vKwQmJWkdsA5g8eLFDAwMNFWKWRYknRpvvK7LgSFgUWl9YRr7tYjYEhF9EdE3d+4l4WRmU6SuEHgdWCZpiaSrgNXAzprey8wqqOVyICLOS9oA/DcwA9gaEYfqeC8zq6a2ewIRsQvYVdffN7PO8C8GzTLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLX2MxCtZFa28+NWM0AnwmYZa/tEJC0SNIrkg5LOiTpgTT+qKQhSfvTY1XnyjWzTqtyOXAe+GpEvCHpOmCfpN1p2+MR8Y3q5ZlZ3doOgYgYBobT8geSjlBMNW5m00hH7glI6gFuAF5LQxskHZC0VdKsTryHmdWjcghIuhbYATwYEe8Dm4HrgV6KM4VNE7xunaQBSQPnzp2rWoaZtalSCEi6kiIAnomIFwAiYiQiLkTEReBJipZkl3DfAbPuUOXbAQFPAUci4rHS+PzSbncCB9svz8zqVuXbgc8AdwNvStqfxh4G1kjqBQI4CdxXqUIzq1WVbwe+D4z387xmew34l4Bml8W/GDTLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMle5DZmkk8AHwAXgfET0SZoNPAf0UMwudFdE/G/V9zKzzuvUmcAfR0RvRPSl9Y3AnohYBuxJ62bWheq6HOgHtqXlbcAdNb2PmVXUiRAI4GVJ+yStS2PzUocigHeAeWNf5L4DZt2hE63Jb4qIIUm/A+yW9FZ5Y0SEpEtm/4yILcAWgL6+Ps8OataQymcCETGUns8CL1I0GxkZ7T+Qns9WfR8zq0fVDkTXpI7ESLoG+DxFs5GdwNq021rgpSrvY2b1qXo5MA94sWhGxBXAtyPivyS9Djwv6V7gFHBXxfcxs5pUCoGIOAH8wTjj7wK3VvnbZjY1/ItBs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy1zb8wlI+hRFb4FRS4G/A2YCfwWMzh76cETsartCM6tV2yEQEUeBXgBJM4AhijkGvwI8HhHf6EiFZlarTl0O3Aocj4hTHfp7ZjZFOhUCq4HtpfUNkg5I2ippVofew8xqUDkEJF0FfBH49zS0Gbie4lJhGNg0wevcfMSsC3TiTOB24I2IGAGIiJGIuBARF4EnKfoQXCIitkREX0T0zZ07twNlmFk7OhECayhdCow2HUnupOhDYGZdqtKU46nhyOeA+0rDX5fUS9Gj8OSYbWbWZar2HfgZ8IkxY3dXqsjMppR/MWiWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZaykE0oShZyUdLI3NlrRb0rH0PCuNS9ITkgbTZKMr6irezKpr9UzgW8BtY8Y2AnsiYhmwJ61DMefgsvRYRzHxqJl1qZZCICJeBX46Zrgf2JaWtwF3lMafjsJeYOaYeQfNrItUuScwLyKG0/I7wLy0vAA4XdrvTBozsy7UkRuDEREUE4u2zH0HzLpDlRAYGT3NT89n0/gQsKi038I09jHuO2DWHaqEwE5gbVpeC7xUGr8nfUuwEnivdNlgZl2mpSnHJW0HPgvMkXQG+Hvga8Dzku4FTgF3pd13AauAQeBDii7FZtalWgqBiFgzwaZbx9k3gPVVijKzqeNfDJplziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmZs0BCZoPPJPkt5KzUVelDQzjfdI+rmk/enxzTqLN7PqWjkT+BaXNh7ZDfxeRPw+8DbwUGnb8YjoTY/7O1OmmdVl0hAYr/FIRLwcEefT6l6KGYXNbBrqxD2BvwS+U1pfIumHkr4n6eaJXuS+A2bdoVIISHoEOA88k4aGgcURcQPw18C3Jf32eK913wGz7tB2CEj6MvBnwF+kGYaJiF9ExLtpeR9wHPhkB+o0s5q0FQKSbgP+FvhiRHxYGp8raUZaXkrRmfhEJwo1s3pM2ndggsYjDwFXA7slAexN3wTcAvyDpF8BF4H7I2JsN2Mz6yKThsAEjUeemmDfHcCOqkWZ2dTxLwbNMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Asc+32HXhU0lCpv8Cq0raHJA1KOirpC3UVbmad0W7fAYDHS/0FdgFIWg6sBj6dXvOvo9ONmVl3aqvvwG/QDzybJhz9MTAI3FihPjOrWZV7AhtSG7KtkmalsQXA6dI+Z9LYJdx3wKw7tBsCm4HrgV6KXgObLvcPuO+AWXdoKwQiYiQiLkTEReBJPjrlHwIWlXZdmMbMrEu123dgfmn1TmD0m4OdwGpJV0taQtF34AfVSjSzOrXbd+CzknqBAE4C9wFExCFJzwOHKdqTrY+IC/WUbmadoNRBrFF9fX0xMDDQdBlm/69J2hcRfWPH/YtBs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy1y7fQeeK/UcOClpfxrvkfTz0rZv1lm8mVU36cxCFH0H/hl4enQgIr40uixpE/Beaf/jEdHbqQLNrF6ThkBEvCqpZ7xtkgTcBfxJZ8sys6lS9Z7AzcBIRBwrjS2R9ENJ35N0c8W/b2Y1a+Vy4DdZA2wvrQ8DiyPiXUl/CPynpE9HxPtjXyhpHbAOYPHixRXLMLN2tX0mIOkK4M+B50bHUvuxd9PyPuA48MnxXu/mI2bdocrlwJ8Cb0XEmdEBSXNHG5BKWkrRd+BEtRLNrE6tfEW4Hfgf4FOSzki6N21azccvBQBuAQ6krwz/A7g/IlptZmpmDWjl24E1E4x/eZyxHcCO6mWZ2VTxLwbNMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Asc61MKrJI0iuSDks6JOmBND5b0m5Jx9LzrDQuSU9IGpR0QNKKuj+EmbWvlTOB88BXI2I5sBJYL2k5sBHYExHLgD1pHeB2imnFllFMJLq541WbWcdMGgIRMRwRb6TlD4AjwAKgH9iWdtsG3JGW+4Gno7AXmClpfscrN7OOuKx7AqkJyQ3Aa8C8iBhOm94B5qXlBcDp0svOpDEz60Ith4CkaynmD3xwbB+BiAggLueNJa2TNCBp4Ny5c5fzUjProJZCQNKVFAHwTES8kIZHRk/z0/PZND4ELCq9fGEa+xj3HTDrDq18OyDgKeBIRDxW2rQTWJuW1wIvlcbvSd8SrATeK102mFmXaaUN2WeAu4E3R1uQAw8DXwOeT30ITlE0JgXYBawCBoEPga90tGIz66hW+g58H9AEm28dZ/8A1lesy8ymiH8xaJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmVMwG1nAR0jngZ8BPmq6lgjlM7/ph+n+G6V4/1PsZfjciLpnauytCAEDSQET0NV1Hu6Z7/TD9P8N0rx+a+Qy+HDDLnEPALHPdFAJbmi6gouleP0z/zzDd64cGPkPX3BMws2Z005mAmTWg8RCQdJuko5IGJW1sup5WSTop6U1J+yUNpLHZknZLOpaeZzVdZ5mkrZLOSjpYGhu35tRL8ol0XA5IWtFc5b+udbz6H5U0lI7DfkmrStseSvUflfSFZqr+iKRFkl6RdFjSIUkPpPFmj0FENPYAZgDHgaXAVcCPgOVN1nQZtZ8E5owZ+zqwMS1vBP6x6TrH1HcLsAI4OFnNFP0kv0PRgm4l8FqX1v8o8Dfj7Ls8/Xu6GliS/p3NaLj++cCKtHwd8Haqs9Fj0PSZwI3AYESciIhfAs8C/Q3XVEU/sC0tbwPuaLCWS0TEq8BPxwxPVHM/8HQU9gIzR1vRN2WC+ifSDzwbEb+IiB9TNMi9sbbiWhARwxHxRlr+ADgCLKDhY9B0CCwATpfWz6Sx6SCAlyXtk7Qujc2Lj9qwvwPMa6a0yzJRzdPp2GxIp8tbS5dgXV2/pB7gBuA1Gj4GTYfAdHZTRKwAbgfWS7qlvDGK87lp9dXLdKwZ2AxcD/QCw8CmZsuZnKRrgR3AgxHxfnlbE8eg6RAYAhaV1hemsa4XEUPp+SzwIsWp5sjo6Vp6PttchS2bqOZpcWwiYiQiLkTEReBJPjrl78r6JV1JEQDPRMQLabjRY9B0CLwOLJO0RNJVwGpgZ8M1TUrSNZKuG10GPg8cpKh9bdptLfBSMxVelolq3gnck+5QrwTeK52ydo0x18h3UhwHKOpfLelqSUuAZcAPprq+MkkCngKORMRjpU3NHoMm75aW7oC+TXH39pGm62mx5qUUd55/BBwarRv4BLAHOAZ8F5jddK1j6t5Occr8K4rry3snqpnijvS/pOPyJtDXpfX/W6rvQPpPM7+0/yOp/qPA7V1Q/00Up/oHgP3psarpY+BfDJplrunLATNrmEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy939d9ESX6O3MjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1764, 3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = NaiveStimulusGenerator(10, (10, 100), dtype=torch.float32)\n",
    "x = gen.generate((20, 20), [])\n",
    "plt.imshow(x.permute(1, 2, 0).numpy())\n",
    "plt.show()\n",
    "\n",
    "every = 5\n",
    "target_positions = [(r * every, c * every) for r, c in itertools.product(range(214 // every), range(214 // every))]\n",
    "reference_positions = []\n",
    "batch = gen.batch_generate(target_positions, reference_positions)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos_array = np.array(target_positions)\n",
    "target_pos_distances = np.linalg.norm(target_pos_array[:, None, :] - target_pos_array[None, :, :], axis=-1)\n",
    "target_pos_distances /= np.max(target_pos_distances)\n",
    "upper_triangle_indices = np.triu_indices_from(target_pos_distances, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataloader = DataLoader(TensorDataset(batch), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model = model.to(device)\n",
    "model.fc_backup = model.fc\n",
    "model.fc = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1764, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = []\n",
    "for b in dataloader:\n",
    "    embeddings.append(model(b[0].to(device)).detach())\n",
    "\n",
    "\n",
    "embeddings = torch.cat(embeddings)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.07058345],\n",
       "       [0.07058345, 1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = nn.CosineSimilarity(dim=-1)\n",
    "embedding_pairwise_cosine = cos(embeddings[:, None, :], embeddings[None, :, :])\n",
    "\n",
    "embedding_cosine_arr = embedding_pairwise_cosine[upper_triangle_indices].cpu().numpy()\n",
    "embedding_cosine_arr = (embedding_cosine_arr - embedding_cosine_arr.mean()) / embedding_cosine_arr.std()\n",
    "\n",
    "target_distance_arr = target_pos_distances[upper_triangle_indices]\n",
    "target_distance_arr = (target_distance_arr - target_distance_arr.mean()) / target_distance_arr.std()\n",
    "\n",
    "np.corrcoef(embedding_cosine_arr, target_distance_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "init must be 'random' or array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-16dbbc44d746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pca'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRANDOM_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtsne_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtsne_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/vlgscratch4/LakeGroup/guy/anaconda3/envs/rainbow/lib/python3.7/site-packages/MulticoreTSNE/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_components, perplexity, early_exaggeration, learning_rate, n_iter, n_iter_early_exag, n_iter_without_progress, min_grad_norm, metric, init, verbose, random_state, method, angle, n_jobs, cheat_metric)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheat_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheat_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"init must be 'random' or array\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"init array must be 2D\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: init must be 'random' or array"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_jobs=4, init='pca', random_state=RANDOM_SEED)\n",
    "tsne_out = tsne.fit_transform(embeddings.cpu().numpy())\n",
    "tsne_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_colors = np.array([x[0] for x in target_positions])\n",
    "row_colors = row_colors / row_colors.max()\n",
    "\n",
    "col_colors = np.array([x[1] for x in target_positions])\n",
    "col_colors = col_colors / col_colors.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "cmap = matplotlib.cm.get_cmap('Spectral_r')\n",
    "\n",
    "row_color_ax = plt.subplot(1, 2, 1)\n",
    "mappable = row_color_ax.scatter(tsne_out[:, 0], tsne_out[:, 1], c=row_colors, cmap=cmap)\n",
    "row_color_ax.set_title('Color by row')\n",
    "\n",
    "col_color_ax = plt.subplot(1, 2, 2)\n",
    "col_color_ax.scatter(tsne_out[:, 0], tsne_out[:, 1], c=col_colors, cmap=cmap)\n",
    "col_color_ax.set_title('Color by column')\n",
    "\n",
    "plt.colorbar(mappable)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = models.vgg16(pretrained=True)\n",
    "vgg.fc_backup = vgg.classifier[6]\n",
    "vgg.classifier[6] = nn.Sequential()\n",
    "vgg = vgg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_embeddings = []\n",
    "for b in dataloader:\n",
    "    vgg_embeddings.append(vgg(b[0].to(device)).detach())\n",
    "\n",
    "\n",
    "vgg_embeddings = torch.cat(vgg_embeddings)\n",
    "vgg_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=-1)\n",
    "cosines = []\n",
    "for i in range(vgg_embeddings.shape[0]):\n",
    "    remainder = vgg_embeddings[i + 1:, :]\n",
    "    current = vgg_embeddings[i,:].repeat(remainder.shape[0], 1)\n",
    "\n",
    "    cosines.append(cos(current, remainder))\n",
    "\n",
    "embedding_cosine_arr = torch.cat(cosines).cpu().numpy()\n",
    "embedding_cosine_arr = (embedding_cosine_arr - embedding_cosine_arr.mean()) / embedding_cosine_arr.std()\n",
    "\n",
    "target_distance_arr = target_pos_distances[upper_triangle_indices]\n",
    "target_distance_arr = (target_distance_arr - target_distance_arr.mean()) / target_distance_arr.std()\n",
    "\n",
    "np.corrcoef(embedding_cosine_arr, target_distance_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_tsne = TSNE(n_jobs=4, init='pca', random_state=RANDOM_SEED)\n",
    "vgg_tsne_out = vgg_tsne.fit_transform(vgg_embeddings.cpu().numpy())\n",
    "vgg_tsne_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "cmap = matplotlib.cm.get_cmap('Spectral_r')\n",
    "\n",
    "row_color_ax = plt.subplot(1, 2, 1)\n",
    "mappable = row_color_ax.scatter(vgg_tsne_out[:, 0], vgg_tsne_out[:, 1], c=row_colors, cmap=cmap)\n",
    "row_color_ax.set_title('Color by row')\n",
    "\n",
    "col_color_ax = plt.subplot(1, 2, 2)\n",
    "col_color_ax.scatter(vgg_tsne_out[:, 0], vgg_tsne_out[:, 1], c=col_colors, cmap=cmap)\n",
    "col_color_ax.set_title('Color by column')\n",
    "\n",
    "plt.colorbar(mappable)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rainbow] *",
   "language": "python",
   "name": "conda-env-rainbow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
