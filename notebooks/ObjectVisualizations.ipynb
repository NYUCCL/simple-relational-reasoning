{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f67e5f593b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_relational_reasoning.datagen import *\n",
    "from simple_relational_reasoning.datagen import IdenticalObjectsRelation\n",
    "from simple_relational_reasoning.models import MLPModel, RelationNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "VisualizationDefinition = namedtuple('VisualizationDefinition', ('name', 'patch_class', 'offset', 'patch_args'))\n",
    "VISUALIZATION_DEFINITIONS = (\n",
    "    VisualizationDefinition('square', mpatches.Rectangle, np.array([0, 0]), (10, 10)),\n",
    "    VisualizationDefinition('circle', mpatches.Circle, np.array([5, 5]), (5, )),\n",
    "    VisualizationDefinition('triangle', mpatches.RegularPolygon, np.array([5, 5]), (3, 6)),\n",
    "    VisualizationDefinition('pentagon', mpatches.RegularPolygon, np.array([5, 5]), (5, 5.5)),\n",
    ")\n",
    "\n",
    "\n",
    "DEFAULT_PATCH_KWARGS = dict(ec='none')\n",
    "DEFAULT_SCALE = 10\n",
    "\n",
    "\n",
    "def object_to_patch(object_tensor, field_slices, \n",
    "                    x_field='x', y_field='y', \n",
    "                    color_field='color', shape_field='shape',\n",
    "                    scale=DEFAULT_SCALE, additional_patch_kwargs=None, \n",
    "                    visualization_definitions=VISUALIZATION_DEFINITIONS):\n",
    "    \n",
    "    patch_kwargs = DEFAULT_PATCH_KWARGS.copy()\n",
    "    if additional_patch_kwargs is not None: \n",
    "        patch_kwargs.update(additional_patch_kwargs)\n",
    "    \n",
    "    x = int(object_tensor[field_slices[x_field]])\n",
    "    y = int(object_tensor[field_slices[y_field]])\n",
    "    position = np.array([x, y]) * scale\n",
    "    shape_index = int(torch.nonzero(object_tensor[field_slices[shape_field]]).squeeze())\n",
    "    color_index = int(torch.nonzero(object_tensor[field_slices[color_field]]).squeeze())\n",
    "    \n",
    "    vis_def = visualization_definitions[shape_index]\n",
    "    patch = vis_def.patch_class(position + vis_def.offset, *vis_def.patch_args,\n",
    "                                **patch_kwargs)\n",
    "    \n",
    "    return patch, color_index\n",
    "\n",
    "\n",
    "def visualize_objects(objects, object_generator, ax=None, x_field='x',\n",
    "                      y_field='y', color_field='color', shape_field='shape',\n",
    "                      scale=DEFAULT_SCALE, figsize=(6, 6), bg_color='black', \n",
    "                      additional_patch_kwargs=None, \n",
    "                      visualization_definitions=VISUALIZATION_DEFINITIONS,\n",
    "                      cmap=plt.cm.tab10, clim=(0, 10)):\n",
    "   \n",
    "    call_show = False\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        call_show = True\n",
    "\n",
    "    x_gen = object_generator.field_generators[x_field]\n",
    "    plt.xlim(x_gen.min_coord * scale, x_gen.max_coord * scale)\n",
    "    y_gen = object_generator.field_generators[y_field]\n",
    "    plt.ylim(y_gen.min_coord * scale, y_gen.max_coord * scale)\n",
    "    ax.set_facecolor(bg_color)\n",
    "    \n",
    "    patches, colors = zip(*[object_to_patch(objects[i], object_generator.field_slices, \n",
    "                                            x_field=x_field, y_field=y_field, \n",
    "                                            color_field=color_field, shape_field=shape_field, \n",
    "                                            scale=scale, additional_patch_kwargs=additional_patch_kwargs,\n",
    "                                            visualization_definitions=visualization_definitions)\n",
    "                            for i in range(objects.shape[0])])\n",
    "    \n",
    "    collection = PatchCollection(patches, cmap=cmap) \n",
    "    collection.set_array(np.array(colors)) \n",
    "    collection.set_clim(*clim)\n",
    "    ax.add_collection(collection)\n",
    "    \n",
    "    ax.get_xaxis().set_ticks([])\n",
    "    ax.get_yaxis().set_ticks([])\n",
    "    \n",
    "    if call_show:\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'object_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-63f81e6943a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m cfgs = ( \n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mobject_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFieldConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int_position'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_coord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mobject_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFieldConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int_position'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_coord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mobject_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFieldConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'color'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'one_hot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mobject_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFieldConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'one_hot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'object_gen' is not defined"
     ]
    }
   ],
   "source": [
    "cfgs = ( \n",
    "    object_gen.FieldConfig('x', 'int_position', dict(max_coord=20)), \n",
    "    object_gen.FieldConfig('y', 'int_position', dict(max_coord=20)), \n",
    "    object_gen.FieldConfig('color', 'one_hot', dict(n_types=4)),\n",
    "    object_gen.FieldConfig('shape', 'one_hot', dict(n_types=4))\n",
    ")\n",
    "\n",
    "# gen = object_gen.ObjectGenerator(4, cfgs, \n",
    "gen = object_gen.SmartBalancedBatchObjectGenerator(4, cfgs, \n",
    "#                                                    MultipleDAdjacentRelation, \n",
    "                                                   ColorAboveColorRelation,\n",
    "#                                                    ObjectCountRelation,\n",
    "                                                   object_dtype=torch.float, label_dtype=torch.long,\n",
    "                                                   max_recursion_depth=100\n",
    "                                                  )\n",
    "\n",
    "X, y = gen(1024)\n",
    "X.shape, y.shape, y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IMAGES_PER_LABEL = 4\n",
    "N_OBJECTS = 4\n",
    "FONTSIZE = 16\n",
    "\n",
    "descriptions = {\n",
    "    MultipleDAdjacentRelation: 'Are any two objects adjacent (L1 distance of 1)?',\n",
    "    ColorAboveColorRelation: 'Is there a blue object above (or at the same height of) all orange objects?',\n",
    "    ObjectCountRelation: 'Are there more blue objects than squares?',\n",
    "    IdenticalObjectsRelation: 'Are any two objects identical (in shape and color)?'\n",
    "}\n",
    "\n",
    "X = {}\n",
    "y = {}\n",
    "\n",
    "for relation_class in (MultipleDAdjacentRelation, ColorAboveColorRelation, \n",
    "                       ObjectCountRelation, \n",
    "#                        IdenticalObjectsRelation\n",
    "                      ):\n",
    "    fig = plt.figure(figsize=(4 * IMAGES_PER_LABEL + 1, 8))\n",
    "    display(Markdown(f'# {relation_class.__name__}'))\n",
    "    display(Markdown(descriptions[relation_class]))\n",
    "    \n",
    "    gen = object_gen.SmartBalancedBatchObjectGenerator(4, cfgs, relation_class,\n",
    "                                                       object_dtype=torch.float, label_dtype=torch.long,\n",
    "                                                       max_recursion_depth=100\n",
    "                                                      )\n",
    "\n",
    "    X[relation_class], y[relation_class] = gen(100)\n",
    "    y[relation_class] = y[relation_class].bool()\n",
    "    positive_indices = np.random.choice(torch.nonzero(y[relation_class]).squeeze(), size=4, replace=False)\n",
    "    negative_indices = np.random.choice(torch.nonzero(~y[relation_class]).squeeze(), size=4, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(positive_indices):\n",
    "        ax = plt.subplot(2, IMAGES_PER_LABEL, i + 1)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Positive Examples', fontsize=FONTSIZE)\n",
    "            \n",
    "        visualize_objects(X[relation_class][idx], gen, ax)\n",
    "        ax.set_title(idx)\n",
    "\n",
    "        \n",
    "    for i, idx in enumerate(negative_indices):\n",
    "        ax = plt.subplot(2, IMAGES_PER_LABEL, i + IMAGES_PER_LABEL + 1)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Negative Examples', fontsize=FONTSIZE)\n",
    "            \n",
    "        visualize_objects(X[relation_class][idx], gen, ax)\n",
    "        ax.set_title(idx)\n",
    "        \n",
    "    plt.show()\n",
    "    display(Markdown(f'------'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generation details\n",
    "\n",
    "* We generate a dataset of $M$ images, each with $N$ objects to be balanced with respect to a particular relation.\n",
    "* Each relation class (see the implementations in `object_relations.py`) knows how to convert a negative example to a positive, but not vice versa. That is, we can change a collections of objects where a relation doesn't hold to one where it does.\n",
    "* First, we sample $M$ images randomly. \n",
    "* If more than $M / 2$ are positive (with respect to the given relation), we resample all of the positive ones, repeating until at least $M / 2$ are negative.\n",
    "* We now have $M_{neg} > M / 2$ negative images. We convert $M_{neg} - M / 2$ of them to be positive, guaranteeing our dataset is balanced 50/50.\n",
    "* The logic above is implemented in the `SmartBalancedBatchObjectGenerator` class in `object_gen.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rainbow]",
   "language": "python",
   "name": "conda-env-rainbow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
