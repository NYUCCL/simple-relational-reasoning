{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../run'))\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from tqdm import tnrange\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fef70ab19b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_relational_reasoning.datagen import *\n",
    "from simple_relational_reasoning.datagen import object_gen\n",
    "from simple_relational_reasoning.models import MLPModel, RelationNetModel\n",
    "\n",
    "import run\n",
    "from defaults import FIELD_CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_TEMPLATE = r'''\\begin{{figure}}[!htb]\n",
    "% \\vspace{{-0.225in}}\n",
    "\\centering\n",
    "\\includegraphics[width=\\linewidth]{{figures/{save_path}}}\n",
    "\\caption{{ {{\\bf FIGURE TITLE.}} FIGURE DESCRIPTION.}}\n",
    "\\label{{fig:{label_name}}}\n",
    "% \\vspace{{-0.2in}}\n",
    "\\end{{figure}}\n",
    "'''\n",
    "WRAPFIGURE_TEMPLATE = r'''\\begin{{wrapfigure}}{{r}}{{0.5\\linewidth}}\n",
    "\\vspace{{-.3in}}\n",
    "\\begin{{spacing}}{{1.0}}\n",
    "\\centering\n",
    "\\includegraphics[width=0.95\\linewidth]{{figures/{save_path}}}\n",
    "\\caption{{ {{\\bf FIGURE TITLE.}} FIGURE DESCRIPTION.}}\n",
    "\\label{{fig:{label_name}}}\n",
    "\\end{{spacing}}\n",
    "% \\vspace{{-.25in}}\n",
    "\\end{{wrapfigure}}'''\n",
    "\n",
    "SAVE_PATH_PREFIX = 'figures'\n",
    "\n",
    "\n",
    "def save_plot(save_path, bbox_inches='tight'):\n",
    "    if save_path is not None:\n",
    "        save_path_no_ext = os.path.splitext(save_path)[0]\n",
    "        print('Figure:\\n')\n",
    "        print(FIGURE_TEMPLATE.format(save_path=save_path, label_name=save_path_no_ext.replace('/', '-').replace('_', '-')))\n",
    "        print('\\nWrapfigure:\\n')\n",
    "        print(WRAPFIGURE_TEMPLATE.format(save_path=save_path, label_name=save_path_no_ext.replace('/', '-').replace('_', '-')))\n",
    "        print('')\n",
    "        \n",
    "        if not save_path.startswith(SAVE_PATH_PREFIX):\n",
    "            save_path = os.path.join(SAVE_PATH_PREFIX, save_path)\n",
    "        \n",
    "        folder, filename = os.path.split(save_path)\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        plt.savefig(save_path, bbox_inches=bbox_inches, facecolor=plt.gcf().get_facecolor(), edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "VisualizationDefinition = namedtuple('VisualizationDefinition', ('name', 'patch_class', 'offset', 'patch_args'))\n",
    "VISUALIZATION_DEFINITIONS = (\n",
    "    VisualizationDefinition('square', mpatches.Rectangle, np.array([0, 0]), (10, 10)),\n",
    "    VisualizationDefinition('circle', mpatches.Ellipse, np.array([5, 5]), (10, 10)),\n",
    "    VisualizationDefinition('triangle', mpatches.RegularPolygon, np.array([5, 5]), (3, 6)),\n",
    "    VisualizationDefinition('pentagon', mpatches.RegularPolygon, np.array([5, 5]), (5, 5.5)),\n",
    ")\n",
    "\n",
    "\n",
    "DEFAULT_PATCH_KWARGS = dict(ec='none')\n",
    "DEFAULT_SCALE = 10\n",
    "\n",
    "\n",
    "def object_to_patch(object_tensor, field_slices, \n",
    "                    x_field='x', y_field='y', \n",
    "                    x_length_field='x_len', y_length_field='y_len',\n",
    "                    color_field='color', shape_field='shape',\n",
    "                    scale=DEFAULT_SCALE, additional_patch_kwargs=None, \n",
    "                    visualization_definitions=VISUALIZATION_DEFINITIONS):\n",
    "    \n",
    "    patch_kwargs = DEFAULT_PATCH_KWARGS.copy()\n",
    "    if additional_patch_kwargs is not None: \n",
    "        patch_kwargs.update(additional_patch_kwargs)\n",
    "    \n",
    "    x = int(object_tensor[field_slices[x_field]])\n",
    "    y = int(object_tensor[field_slices[y_field]])\n",
    "    position = np.array([x, y]) * scale\n",
    "    \n",
    "    shape_index = 0\n",
    "    if shape_field in field_slices:\n",
    "        shape_index = int(torch.nonzero(object_tensor[field_slices[shape_field]]).squeeze())\n",
    "        \n",
    "    color_index = 0\n",
    "    if color_field in field_slices:\n",
    "        color_index = int(torch.nonzero(object_tensor[field_slices[color_field]]).squeeze())\n",
    "        \n",
    "    \n",
    "    vis_def = visualization_definitions[shape_index]\n",
    "    offset = vis_def.offset\n",
    "    patch_args = vis_def.patch_args\n",
    "    \n",
    "    x_len = 1\n",
    "    if x_length_field in field_slices:\n",
    "        x_len = object_tensor[field_slices[x_length_field]]\n",
    "        \n",
    "    y_len = 1\n",
    "    if y_length_field in field_slices:\n",
    "        y_len = object_tensor[field_slices[y_length_field]]\n",
    "        \n",
    "    offset = np.multiply(offset, np.array([x_len, y_len]))\n",
    "    patch_args = [patch_args[0] * x_len, patch_args[1] * y_len] + list(patch_args[2:])\n",
    "    \n",
    "    patch = vis_def.patch_class(position + offset, *patch_args, **patch_kwargs)\n",
    "    \n",
    "    return patch, color_index\n",
    "\n",
    "\n",
    "def visualize_objects(objects, object_generator, ax=None, x_field='x',\n",
    "                      y_field='y', color_field='color', shape_field='shape',\n",
    "                      scale=DEFAULT_SCALE, figsize=(6, 6), bg_color='black', \n",
    "                      additional_patch_kwargs=None, \n",
    "                      visualization_definitions=VISUALIZATION_DEFINITIONS,\n",
    "                      cmap=plt.cm.tab10, clim=(0, 10)):\n",
    "   \n",
    "    call_show = False\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        call_show = True\n",
    "\n",
    "    x_gen = object_generator.field_generators[x_field]\n",
    "    plt.xlim(x_gen.min_coord * scale, x_gen.max_coord * scale)\n",
    "    y_gen = object_generator.field_generators[y_field]\n",
    "    plt.ylim(y_gen.min_coord * scale, y_gen.max_coord * scale)\n",
    "    ax.set_facecolor(bg_color)\n",
    "    \n",
    "    patches, colors = zip(*[object_to_patch(objects[i], object_generator.field_slices, \n",
    "                                            x_field=x_field, y_field=y_field, \n",
    "                                            color_field=color_field, shape_field=shape_field, \n",
    "                                            scale=scale, additional_patch_kwargs=additional_patch_kwargs,\n",
    "                                            visualization_definitions=visualization_definitions)\n",
    "                            for i in range(objects.shape[0])])\n",
    "    \n",
    "    collection = PatchCollection(patches, cmap=cmap) \n",
    "    collection.set_array(np.array(colors)) \n",
    "    collection.set_edgecolor('white')\n",
    "    collection.set_clim(*clim)\n",
    "    ax.add_collection(collection)\n",
    "    \n",
    "    ax.get_xaxis().set_ticks([])\n",
    "    ax.get_yaxis().set_ticks([])\n",
    "    \n",
    "    if call_show:\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'object_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-155b1331ab89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m QUINN_FIELD_CONFIG_WITH_SIZE = (\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mobject_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFieldConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int_position'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_coord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mobject_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFieldConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int_position'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_coord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mobject_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFieldConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x_len'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int_position'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_coord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_coord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mobject_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFieldConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'color'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'one_hot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'object_gen' is not defined"
     ]
    }
   ],
   "source": [
    "QUINN_FIELD_CONFIG_WITH_SIZE = (\n",
    "    object_gen.FieldConfig('x', 'int_position', dict(max_coord=20)),\n",
    "    object_gen.FieldConfig('y', 'int_position', dict(max_coord=20)),\n",
    "    object_gen.FieldConfig('x_len', 'int_position', dict(min_coord=1, max_coord=10)),\n",
    "    object_gen.FieldConfig('color', 'one_hot', dict(n_types=2)),\n",
    ")\n",
    "QUINN_FAUX_GENERATOR_WITH_SIZE = ObjectGenerator(1, QUINN_FIELD_CONFIG_WITH_SIZE, BetweenRelation)\n",
    "\n",
    "QUINN_FIELD_CONFIG_WITHOUT_SIZE = (\n",
    "    object_gen.FieldConfig('x', 'int_position', dict(max_coord=20)),\n",
    "    object_gen.FieldConfig('y', 'int_position', dict(max_coord=20)),\n",
    "    object_gen.FieldConfig('color', 'one_hot', dict(n_types=2)),\n",
    ")\n",
    "\n",
    "QUINN_FAUX_GENERATOR_WITHOUT_SIZE = ObjectGenerator(1, QUINN_FIELD_CONFIG_WITHOUT_SIZE, BetweenRelation)\n",
    "\n",
    "FAUX_GENERATORS = {\n",
    "    ObjectGeneratorWithoutSize: QUINN_FAUX_GENERATOR_WITHOUT_SIZE,\n",
    "    ObjectGeneratorWithSize: QUINN_FAUX_GENERATOR_WITH_SIZE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "above vs. below using objects without size\n",
      "Of the reference object locations, train: 273, test: 31 \n",
      "Training set size: 5733 | Test set without middle: 1650 | Middle set size: 5472\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'FAUX_GENERATORS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-86e181afd4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_panels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml_i\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mEXAMPLES_PER_CLASS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mex_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'C = {label} (#{ex})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mvisualize_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFAUX_GENERATORS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerator_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FAUX_GENERATORS' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2916x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "REFERENCE_OBJECT_SIZE = 9\n",
    "TARGET_OBJECT_SIZE = 1\n",
    "ADD_NEITHER = True\n",
    "X_MAX = 25\n",
    "Y_MAX = 25\n",
    "SEED = 33\n",
    "PROP_TRAIN_REF_LOCATIONS = 0.90\n",
    "N_TRAIN_TARGET_OBJECT_LOCATIONS = 7\n",
    "\n",
    "\n",
    "EXAMPLES_PER_CLASS = 3\n",
    "\n",
    "NAMES = {\n",
    "    AboveBelowReferenceInductiveBias: 'above vs. below',\n",
    "    BetweenReferenceInductiveBias: 'above vs. below vs. between',\n",
    "    ObjectGeneratorWithoutSize: 'objects without size',\n",
    "    ObjectGeneratorWithSize: 'objects with size'\n",
    "}\n",
    "\n",
    "DATASETS = {}\n",
    "\n",
    "\n",
    "for dataset_class in (AboveBelowReferenceInductiveBias, BetweenReferenceInductiveBias):\n",
    "    for generator_class in (ObjectGeneratorWithoutSize, ObjectGeneratorWithSize):\n",
    "        title = f'{NAMES[dataset_class]} using {NAMES[generator_class]}'\n",
    "        print(title)\n",
    "        gen = generator_class(SEED, REFERENCE_OBJECT_SIZE, TARGET_OBJECT_SIZE)\n",
    "        dataset = dataset_class(gen, X_MAX, Y_MAX, SEED, prop_train_reference_object_locations=PROP_TRAIN_REF_LOCATIONS,\n",
    "                               n_train_target_object_locations=N_TRAIN_TARGET_OBJECT_LOCATIONS)\n",
    "        \n",
    "        DATASETS[(dataset_class, generator_class)] = dataset\n",
    "        \n",
    "        train = dataset.get_training_dataset()\n",
    "        label_arr = np.array(train.labels)\n",
    "        unique_labels, unique_counts = np.unique(label_arr, return_counts=True)\n",
    "#         print(len(train), unique_labels, unique_counts)\n",
    "        \n",
    "        test_datasets = dataset.get_test_datasets()\n",
    "#         print([(key, len(test_datasets[key])) for key in test_datasets])\n",
    "        \n",
    "        test_without_middle_size = sum([len(test_datasets[key]) for key in test_datasets if 'middle' not in key]) \n",
    "        test_middle_size = sum([len(test_datasets[key]) for key in test_datasets if 'middle' in key])\n",
    "        \n",
    "        print(f'Of the reference object locations, train: {len(dataset.train_reference_object_locations)}, test: {len(dataset.test_reference_object_locations)} ')\n",
    "        \n",
    "        print(f'Training set size: {len(train)} | Test set without middle: {test_without_middle_size} | Middle set size: {test_middle_size}')\n",
    "        \n",
    "        n_labels = len(unique_labels)\n",
    "        n_panels = n_labels * EXAMPLES_PER_CLASS\n",
    "        plt.figure(figsize=(4.5 * n_panels, 4))\n",
    "        plt.suptitle(title.title())\n",
    "        \n",
    "        for l_i, label in enumerate(unique_labels):\n",
    "            indices = np.random.permutation(np.argwhere(label_arr == label))[:EXAMPLES_PER_CLASS].squeeze()\n",
    "            for ex_i, ex in enumerate(indices):\n",
    "                ax = plt.subplot(1, n_panels, 1 + (l_i * EXAMPLES_PER_CLASS) + ex_i)\n",
    "                ax.set_title(f'C = {label} (#{ex})')\n",
    "                visualize_objects(train[ex][0], FAUX_GENERATORS[generator_class], ax=ax)\n",
    "            \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE_OBJECT_SIZE = 9\n",
    "TARGET_OBJECT_SIZE = 1\n",
    "ADD_NEITHER = True\n",
    "X_MAX = 18\n",
    "Y_MAX = 18\n",
    "SEED = 33\n",
    "EXAMPLES_PER_CLASS = 4\n",
    "PROP_TRAIN_REF_LOCATIONS = 0.90\n",
    "PROP_TRAIN_TARGET_LOCATIONS = 0.75\n",
    "\n",
    "indices = {}\n",
    "\n",
    "ONE_OR_TWO_DATASETS = {}\n",
    "\n",
    "\n",
    "for generator_class in (ObjectGeneratorWithoutSize, ObjectGeneratorWithSize):\n",
    "    for two_reference_objects in (False, True):\n",
    "        title = f'{two_reference_objects and \"Two reference objects\" or \"One reference object\"} using {NAMES[generator_class]}'\n",
    "        print(title)\n",
    "        gen = generator_class(SEED, REFERENCE_OBJECT_SIZE, TARGET_OBJECT_SIZE)\n",
    "        dataset = OneOrTwoReferenceObjects(gen, X_MAX, Y_MAX, SEED, two_reference_objects=two_reference_objects,\n",
    "                                           prop_train_reference_object_locations=PROP_TRAIN_REF_LOCATIONS,\n",
    "                                           prop_train_target_object_locations=PROP_TRAIN_TARGET_LOCATIONS)\n",
    "        \n",
    "        ONE_OR_TWO_DATASETS[generator_class, two_reference_objects] = dataset\n",
    "        \n",
    "        train = dataset.get_training_dataset()\n",
    "        label_arr = np.array(train.labels)\n",
    "        unique_labels, unique_counts = np.unique(label_arr, return_counts=True)\n",
    "#         print(len(train), unique_labels, unique_counts)\n",
    "        \n",
    "        test_datasets = dataset.get_test_datasets()\n",
    "#         print([(key, len(test_datasets[key])) for key in test_datasets])\n",
    "\n",
    "        print(f'Of the reference object locations, train: {len(dataset.train_reference_object_locations)}, test: {len(dataset.test_reference_object_locations)} ')\n",
    "\n",
    "        total_test_size = sum([len(test_datasets[key]) for key in test_datasets]) \n",
    "        print(f'Training set size: {len(train)} | Test set size: {total_test_size}')\n",
    "        \n",
    "        n_labels = len(unique_labels)\n",
    "        n_panels = n_labels * EXAMPLES_PER_CLASS\n",
    "        plt.figure(figsize=(4.5 * n_panels, 4))\n",
    "        plt.suptitle(title.title())\n",
    "        \n",
    "        for l_i, label in enumerate(unique_labels):\n",
    "            if label not in indices:\n",
    "                indices[label] = np.random.permutation(np.argwhere(label_arr == label))[:EXAMPLES_PER_CLASS].squeeze()\n",
    "                \n",
    "            for ex_i, ex in enumerate(indices[label]):\n",
    "                ax = plt.subplot(1, n_panels, 1 + (l_i * EXAMPLES_PER_CLASS) + ex_i)\n",
    "                ax.set_title(f'C = {label_arr[ex]} (#{ex})')\n",
    "                visualize_objects(train[ex][0], FAUX_GENERATORS[generator_class], ax=ax)\n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "    indices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'AboveBelowReferenceInductiveBias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e591042f566d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAboveBelowReferenceInductiveBias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBetweenReferenceInductiveBias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgenerator_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mObjectGeneratorWithoutSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mObjectGeneratorWithSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0madd_neither\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AboveBelowReferenceInductiveBias' is not defined"
     ]
    }
   ],
   "source": [
    "for seed in range(100, 200):\n",
    "    if seed % 10 == 0:\n",
    "        print(seed)\n",
    "        \n",
    "    for dataset_class in (AboveBelowReferenceInductiveBias, BetweenReferenceInductiveBias):\n",
    "        for generator_class in (ObjectGeneratorWithoutSize, ObjectGeneratorWithSize):\n",
    "            for add_neither in (False, True):\n",
    "                title = f'{NAMES[dataset_class]} using {NAMES[generator_class]}'\n",
    "                gen = generator_class(seed, REFERENCE_OBJECT_SIZE, TARGET_OBJECT_SIZE)\n",
    "                dataset = dataset_class(gen, X_MAX, Y_MAX, seed, prop_train_reference_object_locations=PROP_TRAIN_REF_LOCATIONS,\n",
    "                                       n_train_target_object_locations=N_TRAIN_TARGET_OBJECT_LOCATIONS,\n",
    "                                       add_neither_train=add_neither, add_neither_test=add_neither)\n",
    "\n",
    "                train = dataset.get_training_dataset()\n",
    "                if train.objects.max() > 24:\n",
    "                    print(seed, dataset_class, generator_class, add_neither)\n",
    "                    break\n",
    "                    \n",
    "                for test_key, test_set in dataset.get_test_datasets().items():\n",
    "                    if test_set.objects.max() > 24:\n",
    "                        print(seed, dataset_class, generator_class, add_neither, test_key)\n",
    "                        break\n",
    "                        \n",
    "                spatial_dataset = dataset_class(gen, X_MAX, Y_MAX, seed, prop_train_reference_object_locations=PROP_TRAIN_REF_LOCATIONS,\n",
    "                                       n_train_target_object_locations=N_TRAIN_TARGET_OBJECT_LOCATIONS,\n",
    "                                       add_neither_train=add_neither, add_neither_test=add_neither, spatial_dataset=True)\n",
    "\n",
    "                spatial_train = spatial_dataset.get_training_dataset()\n",
    "                if spatial_train.spatial_objects.max() > 24:\n",
    "                    print('Spatial', seed, dataset_class, generator_class, add_neither)\n",
    "                    break\n",
    "                    \n",
    "                for test_key, test_set in spatial_dataset.get_test_datasets().items():\n",
    "                    if test_set.spatial_objects.max() > 24:\n",
    "                        print('Spatial', seed, dataset_class, generator_class, add_neither, test_key)\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "START = 0\n",
    "\n",
    "plt.figure(figsize=(4.5 * N, 4))\n",
    "\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(1, N, i + 1)\n",
    "    ax.set_title(f'C = {label} (#{ex})')\n",
    "    visualize_objects(train[START + (i * 2)][0], FAUX_GENERATORS[generator_class], ax=ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_with_size = ObjectGeneratorWithSize(9, 1)\n",
    "above_below_dataset_size = AboveBelowReferenceInductiveBias(gen_with_size, 20, 20, 33)\n",
    "train_dataset_size = above_below_dataset_size.get_training_dataset()\n",
    "print(len(train_dataset_size))\n",
    "test_datasets_size = above_below_dataset_size.get_test_datasets()\n",
    "print([(key, len(test_datasets_size[key])) for key in test_datasets_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_objects(train_dataset_size[12][0], QUINN_FAUX_GENERATOR_WITH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_dataset.labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    ax = plt.subplot(1, 4, i + 1)    \n",
    "    visualize_objects(generate_above(gen), gen, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "y = {}\n",
    "object_generators = {}\n",
    "positive_indices = {}\n",
    "negative_indices = {}\n",
    "\n",
    "for num_objects in (5, 10):\n",
    "    \n",
    "    for i, relation in enumerate(run.RELATION_NAMES_TO_CLASSES):\n",
    "        key = (num_objects, relation)\n",
    "        \n",
    "        relation_class = run.RELATION_NAMES_TO_CLASSES[relation]\n",
    "        object_generator = object_gen.SmartBalancedBatchObjectGenerator(\n",
    "            num_objects, run.FIELD_CONFIGURATIONS['default'], relation_class)\n",
    "        object_generators[key] = object_generator\n",
    "            \n",
    "        X[key], y[key] = object_generator(100)\n",
    "        y[key] = y[key].bool()\n",
    "        \n",
    "        positive_indices[key] = torch.nonzero(y[key]).squeeze()\n",
    "        negative_indices[key] = torch.nonzero(~y[key]).squeeze()\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROWS = 2\n",
    "NUM_RELATIONS = len(run.RELATION_NAMES_TO_CLASSES)\n",
    "FONTSIZE = 16\n",
    "\n",
    "pos_idx_choices = defaultdict(lambda: 0)\n",
    "neg_idx_choices = defaultdict(lambda: 0)\n",
    "\n",
    "pos_idx_choices[(5, 'above')] = 1\n",
    "pos_idx_choices[(5, 'count')] = 1\n",
    "\n",
    "for num_objects in (5, 10):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "    \n",
    "    for i, relation in enumerate(run.RELATION_NAMES_TO_CLASSES):\n",
    "        key = (num_objects, relation)\n",
    "            \n",
    "        pos_idx = positive_indices[key][pos_idx_choices[key]]\n",
    "        neg_idx = negative_indices[key][neg_idx_choices[key]]\n",
    "    \n",
    "        pos_ax = plt.subplot(NUM_ROWS, NUM_RELATIONS, i + 1)\n",
    "        if i == 0:\n",
    "            pos_ax.set_ylabel('Positive Examples', fontsize=FONTSIZE)\n",
    "        visualize_objects(X[key][pos_idx], object_generators[key], pos_ax)\n",
    "        pos_ax.set_title(relation.title(), fontsize=FONTSIZE)\n",
    "    \n",
    "        neg_ax = plt.subplot(NUM_ROWS, NUM_RELATIONS, NUM_RELATIONS + i + 1)\n",
    "        if i == 0:\n",
    "            neg_ax.set_ylabel('Negative Examples', fontsize=FONTSIZE)\n",
    "        visualize_objects(X[key][neg_idx], object_generators[key], neg_ax)\n",
    "    \n",
    "#     save_plot(f'example_images_{num_objects}.pdf')\n",
    "        \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking a stab at the Quinn-like relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(arr):\n",
    "    one_hot = np.zeros((arr.size, int(max(arr) + 1)))\n",
    "    one_hot[np.arange(arr.size), arr] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def generate_above(object_generator, line_length=4, \n",
    "                   x_field='x', y_field='y', color_field='color', shape_field='shape',):\n",
    "    x_gen = object_generator.field_generators[x_field]\n",
    "    y_gen = object_generator.field_generators[y_field]\n",
    "    \n",
    "    line_x_start = np.random.randint(0, x_gen.max_coord - line_length)\n",
    "    line_x_end = line_x_start + line_length  # exclusive\n",
    "    line_y = np.random.randint(0, y_gen.max_coord - 1)\n",
    "        \n",
    "    target_x = np.random.randint(line_x_start, line_x_end)\n",
    "    target_y = np.random.randint(line_y + 1, min(line_y + 3, y_gen.max_coord))\n",
    "    \n",
    "    line_color = np.random.randint(0, 2)\n",
    "    target_color = 1 - line_color\n",
    "    shape = np.random.randint(0, 2)\n",
    "    \n",
    "    x = np.expand_dims(np.append(np.arange(line_x_start, line_x_end), target_x), -1)\n",
    "    y = np.expand_dims(np.append(np.repeat(line_y, line_length), target_y), -1)\n",
    "    color = to_one_hot(np.append(np.repeat(line_color, line_length), target_color))\n",
    "    shape = to_one_hot(np.repeat(shape, line_length + 1))\n",
    "    \n",
    "    return torch.from_numpy(np.concatenate((x, y, color, shape), axis=-1)).to(torch.float)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "gen = list(object_generators.values())[0]\n",
    "\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(1, 4, i + 1)    \n",
    "    visualize_objects(generate_above(gen), gen, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_config_with_length = (\n",
    "    object_gen.FieldConfig('x', 'int_position', dict(max_coord=16)),\n",
    "    object_gen.FieldConfig('y', 'int_position', dict(max_coord=16)),\n",
    "    object_gen.FieldConfig('x_len', 'int_position', dict(min_coord=1, max_coord=4)),\n",
    "    object_gen.FieldConfig('y_len', 'int_position', dict(min_coord=1, max_coord=4)),\n",
    "    object_gen.FieldConfig('color', 'one_hot', dict(n_types=2)),\n",
    "    object_gen.FieldConfig('shape', 'one_hot', dict(n_types=2))\n",
    ")\n",
    "\n",
    "gen_with_length = ObjectGenerator(2, field_config_with_length, MultipleDAdjacentRelation)\n",
    "\n",
    "\n",
    "def generate_above_with_length(object_generator, line_length=4, \n",
    "                   x_field='x', y_field='y', color_field='color', shape_field='shape',):\n",
    "    x_gen = object_generator.field_generators[x_field]\n",
    "    y_gen = object_generator.field_generators[y_field]\n",
    "    \n",
    "    line_x_start = np.random.randint(0, x_gen.max_coord - line_length)\n",
    "    line_y = np.random.randint(0, y_gen.max_coord - 1)\n",
    "        \n",
    "    target_x = np.random.randint(line_x_start, line_x_start + line_length)\n",
    "    target_y = np.random.randint(line_y + 1, min(line_y + 3, y_gen.max_coord))\n",
    "    \n",
    "    line_color = np.random.randint(0, 2)\n",
    "    target_color = 1 - line_color\n",
    "    shape = np.random.randint(0, 2)\n",
    "    \n",
    "    x = np.expand_dims(np.array([line_x_start, target_x]), -1)\n",
    "    y = np.expand_dims(np.array([line_y, target_y]), -1)\n",
    "    x_len = np.expand_dims(np.array([line_length, 1]), -1)\n",
    "    y_len = np.expand_dims(np.array([1, 1]), -1)\n",
    "    color = to_one_hot(np.array([line_color, target_color]))\n",
    "    shape = to_one_hot(np.repeat(shape, 2))\n",
    "    \n",
    "    return torch.from_numpy(np.concatenate((x, y, x_len, y_len, color, shape), axis=-1)).to(torch.float)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    visualize_objects(generate_above_with_length(gen_with_length), gen_with_length, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "* Do we want distractor objects?\n",
    "* How much position variation do we want? In other words, if the line is 4 units long, what should the length of the entire axis be?\n",
    "* What do we train on, and what do we test on?\n",
    "* Do we need more than two colors and shapes?\n",
    "* Do we want variation in the distance between the objects, too? Or should they always be adjacent? \n",
    "* **The positives are easy. What are the negatives?? What are the generalization tests??**\n",
    "* **Come up with example stimuli for each of the different parts of the experiments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equivalent of Figure 3.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_config_with_length = (\n",
    "    object_gen.FieldConfig('x', 'int_position', dict(max_coord=20)),\n",
    "    object_gen.FieldConfig('y', 'int_position', dict(max_coord=20)),\n",
    "    object_gen.FieldConfig('x_len', 'int_position', dict(min_coord=1, max_coord=4)),\n",
    "    object_gen.FieldConfig('y_len', 'int_position', dict(min_coord=1, max_coord=4)),\n",
    "    object_gen.FieldConfig('color', 'one_hot', dict(n_types=3)),\n",
    "    object_gen.FieldConfig('shape', 'one_hot', dict(n_types=2))\n",
    ")\n",
    "\n",
    "gen_with_length = ObjectGenerator(2, field_config_with_length, MultipleDAdjacentRelation)\n",
    "\n",
    "\n",
    "def combine(*args):\n",
    "    print([len(x) for x in args])\n",
    "    arrays = []\n",
    "    for arr in args:\n",
    "        if len(arr.shape) == 1:\n",
    "            arr = np.expand_dims(arr, -1)\n",
    "        \n",
    "        arrays.append(arr)\n",
    "        \n",
    "    return torch.from_numpy(np.concatenate(arrays, axis=-1)).to(torch.float)\n",
    "\n",
    "\n",
    "def generate_3_2(object_generator, line_length=9, \n",
    "                   x_field='x', y_field='y', color_field='color', shape_field='shape',):\n",
    "    x_gen = object_generator.field_generators[x_field]\n",
    "    y_gen = object_generator.field_generators[y_field]\n",
    "    \n",
    "    line_x_start = np.random.randint(0, x_gen.max_coord - line_length)\n",
    "    line_x_end = line_x_start + line_length\n",
    "    line_y = np.random.randint(3, y_gen.max_coord - 4)\n",
    "        \n",
    "#     target_x = np.random.randint(line_x_start, line_x_start + line_length)\n",
    "#     target_y = np.random.randint(line_y + 1, min(line_y + 3, y_gen.max_coord))\n",
    "\n",
    "    above_x = np.arange(line_x_start, line_x_start + 3)\n",
    "    above_y = np.arange(line_y + 1, line_y + 4)\n",
    "    above_x_values, above_y_values = zip(*itertools.product(above_x, above_y))\n",
    "    \n",
    "    below_x = np.arange(line_x_end - 3, line_x_end)\n",
    "    below_y = np.arange(line_y - 3, line_y)\n",
    "    below_x_values, below_y_values = zip(*itertools.product(below_x, below_y))\n",
    "\n",
    "    line_color = 0\n",
    "    above_color = 1\n",
    "    below_color = 2\n",
    "    shape = 0\n",
    "    \n",
    "    x = np.array([line_x_start] + list(above_x_values) + list(below_x_values))\n",
    "    y = np.array([line_y] + list(above_y_values) + list(below_y_values))\n",
    "    x_len = np.array([line_length] + [1] * (len(above_x_values) + len(below_x_values)))\n",
    "    y_len = np.repeat(1, 1 + len(above_y_values) + len(below_y_values)) \n",
    "    color = to_one_hot(np.array([line_color] + [above_color] * len(above_x_values) + [below_color] * len(below_x_values)))\n",
    "    shape = to_one_hot(np.repeat(shape, 1 + len(above_y_values) + len(below_y_values)))\n",
    "    \n",
    "    return combine(x, y, x_len, y_len, color, shape)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    visualize_objects(generate_3_2(gen_with_length), gen_with_length, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3_3(object_generator, line_length=9, \n",
    "                   x_field='x', y_field='y', color_field='color', shape_field='shape',):\n",
    "    x_gen = object_generator.field_generators[x_field]\n",
    "    y_gen = object_generator.field_generators[y_field]\n",
    "    \n",
    "    line_x_start = np.random.randint(0, x_gen.max_coord - line_length)\n",
    "    line_x_end = line_x_start + line_length\n",
    "    line_y = np.random.randint(3, y_gen.max_coord - 4)\n",
    "        \n",
    "#     target_x = np.random.randint(line_x_start, line_x_start + line_length)\n",
    "#     target_y = np.random.randint(line_y + 1, min(line_y + 3, y_gen.max_coord))\n",
    "\n",
    "    above_x = np.arange(line_x_start, line_x_start + 3)\n",
    "    above_y = np.arange(line_y + 1, line_y + 4)\n",
    "    above_x_values, above_y_values = zip(*itertools.product(above_x, above_y))\n",
    "    \n",
    "    below_x = np.arange(line_x_end - 3, line_x_end)\n",
    "    below_y = np.arange(line_y - 3, line_y)\n",
    "    below_x_values, below_y_values = zip(*itertools.product(below_x, below_y))\n",
    "\n",
    "    line_color = 0\n",
    "    above_color = 1\n",
    "    below_color = 2\n",
    "    shape = 0\n",
    "    \n",
    "    x = np.array(list(range(line_x_start, line_x_end)) + list(above_x_values) + list(below_x_values))\n",
    "    y = np.array([line_y] * line_length + list(above_y_values) + list(below_y_values))\n",
    "    x_len = np.array([1] * (line_length + len(above_x_values) + len(below_x_values)))\n",
    "    y_len = np.repeat(1, line_length + len(above_y_values) + len(below_y_values)) \n",
    "    color = to_one_hot(np.array([line_color] * line_length + [above_color] * len(above_x_values) + [below_color] * len(below_x_values)))\n",
    "    shape = to_one_hot(np.repeat(shape, line_length + len(above_y_values) + len(below_y_values)))\n",
    "    \n",
    "    return combine(x, y, x_len, y_len, color, shape)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    visualize_objects(generate_3_3(gen_with_length), gen_with_length, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3_4(object_generator, line_length=9, \n",
    "                   x_field='x', y_field='y', color_field='color', shape_field='shape',):\n",
    "    x_gen = object_generator.field_generators[x_field]\n",
    "    y_gen = object_generator.field_generators[y_field]\n",
    "    \n",
    "    line_x_start = np.random.randint(0, x_gen.max_coord - line_length)\n",
    "    line_x_end = line_x_start + line_length\n",
    "    bottom_line_y = np.random.randint(3, y_gen.max_coord - 7)\n",
    "    top_line_y = bottom_line_y + 4\n",
    "        \n",
    "#     target_x = np.random.randint(line_x_start, line_x_start + line_length)\n",
    "#     target_y = np.random.randint(line_y + 1, min(line_y + 3, y_gen.max_coord))\n",
    "\n",
    "    between_x = np.arange(line_x_start, line_x_start + 3)\n",
    "    between_y = np.arange(bottom_line_y + 1, top_line_y)\n",
    "    between_x_values, between_y_values = zip(*itertools.product(between_x, between_y))\n",
    "\n",
    "#     above_x = np.arange(line_x_start, line_x_start + 3)\n",
    "    above_x = np.arange(line_x_end - 3, line_x_end)\n",
    "    above_y = np.arange(top_line_y + 1, top_line_y + 4)\n",
    "    above_x_values, above_y_values = zip(*itertools.product(above_x, above_y))\n",
    "    \n",
    "    below_x = np.arange(line_x_end - 3, line_x_end)\n",
    "    below_y = np.arange(bottom_line_y - 3, bottom_line_y)\n",
    "    below_x_values, below_y_values = zip(*itertools.product(below_x, below_y))\n",
    "\n",
    "    line_color = 0\n",
    "    between_color = 1\n",
    "    above_below_color = 2\n",
    "    shape = 0\n",
    "    \n",
    "    x = np.array(list(range(line_x_start, line_x_end)) + \n",
    "                 list(range(line_x_start, line_x_end)) + \n",
    "                 list(between_x_values) + list(above_x_values) + list(below_x_values))\n",
    "    y = np.array([bottom_line_y] * line_length + \n",
    "                 [top_line_y] * line_length +\n",
    "                 list(between_y_values) + list(above_y_values) + list(below_y_values))\n",
    "    x_len = np.repeat(1, line_length * 2 + len(between_x_values) + len(above_x_values) + len(below_x_values))\n",
    "    y_len = np.repeat(1, line_length * 2 + len(between_y_values) + len(above_y_values) + len(below_y_values)) \n",
    "    color = to_one_hot(np.array([line_color] * line_length * 2 + \n",
    "                                [between_color] * len(between_x_values) + \n",
    "                                [above_below_color] * (len(below_x_values) + len(below_y_values))))\n",
    "    shape = to_one_hot(np.repeat(shape, line_length * 2 + len(between_y_values) + len(above_y_values) + len(below_y_values)))\n",
    "    \n",
    "    return combine(x, y, x_len, y_len, color, shape)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    visualize_objects(generate_3_4(gen_with_length), gen_with_length, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_config_with_more_colors = (\n",
    "    object_gen.FieldConfig('x', 'int_position', dict(max_coord=20)),\n",
    "    object_gen.FieldConfig('y', 'int_position', dict(max_coord=20)),\n",
    "    object_gen.FieldConfig('x_len', 'int_position', dict(min_coord=1, max_coord=4)),\n",
    "    object_gen.FieldConfig('y_len', 'int_position', dict(min_coord=1, max_coord=4)),\n",
    "    object_gen.FieldConfig('color', 'one_hot', dict(n_types=5)),\n",
    "    object_gen.FieldConfig('shape', 'one_hot', dict(n_types=2))\n",
    ")\n",
    "\n",
    "gen_with_more_colors = ObjectGenerator(2, field_config_with_more_colors, MultipleDAdjacentRelation)\n",
    "\n",
    "def generate_3_5(object_generator, line_length=9, \n",
    "                   x_field='x', y_field='y', color_field='color', shape_field='shape',):\n",
    "    x_gen = object_generator.field_generators[x_field]\n",
    "    y_gen = object_generator.field_generators[y_field]\n",
    "    color_gen = object_generator.field_generators[color_field]\n",
    "    \n",
    "    line_x_start = np.random.randint(0, x_gen.max_coord - line_length)\n",
    "    line_x_end = line_x_start + line_length\n",
    "    line_y = np.random.randint(3, y_gen.max_coord - 4)\n",
    "        \n",
    "#     target_x = np.random.randint(line_x_start, line_x_start + line_length)\n",
    "#     target_y = np.random.randint(line_y + 1, min(line_y + 3, y_gen.max_coord))\n",
    "\n",
    "    above_x = np.arange(line_x_start, line_x_start + 3)\n",
    "    above_y = np.arange(line_y + 1, line_y + 4)\n",
    "    above_x_values, above_y_values = zip(*itertools.product(above_x, above_y))\n",
    "    \n",
    "    below_x = np.arange(line_x_end - 3, line_x_end)\n",
    "    below_y = np.arange(line_y - 3, line_y)\n",
    "    below_x_values, below_y_values = zip(*itertools.product(below_x, below_y))\n",
    "\n",
    "    line_color = 0\n",
    "    above_colors = list(np.random.choice(np.arange(1, color_gen.n_types), len(above_x_values)))\n",
    "    below_colors = list(np.random.choice(np.arange(1, color_gen.n_types), len(below_x_values)))\n",
    "    shape = 0\n",
    "    \n",
    "    x = np.array(list(range(line_x_start, line_x_end)) + list(above_x_values) + list(below_x_values))\n",
    "    y = np.array([line_y] * line_length + list(above_y_values) + list(below_y_values))\n",
    "    x_len = np.array([1] * (line_length + len(above_x_values) + len(below_x_values)))\n",
    "    y_len = np.repeat(1, line_length + len(above_y_values) + len(below_y_values)) \n",
    "    color = to_one_hot(np.array([line_color] * line_length + above_colors + below_colors))\n",
    "    shape = to_one_hot(np.repeat(shape, line_length + len(above_y_values) + len(below_y_values)))\n",
    "    \n",
    "    return combine(x, y, x_len, y_len, color, shape)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    visualize_objects(generate_3_5(gen_with_more_colors), gen_with_more_colors, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3_6(object_generator, line_length=9, \n",
    "                   x_field='x', y_field='y', color_field='color', shape_field='shape',):\n",
    "    x_gen = object_generator.field_generators[x_field]\n",
    "    y_gen = object_generator.field_generators[y_field]\n",
    "    color_gen = object_generator.field_generators[color_field]\n",
    "    \n",
    "    line_x_start = np.random.randint(0, x_gen.max_coord - line_length)\n",
    "    line_x_end = line_x_start + line_length\n",
    "    bottom_line_y = np.random.randint(3, y_gen.max_coord - 7)\n",
    "    top_line_y = bottom_line_y + 4\n",
    "        \n",
    "#     target_x = np.random.randint(line_x_start, line_x_start + line_length)\n",
    "#     target_y = np.random.randint(line_y + 1, min(line_y + 3, y_gen.max_coord))\n",
    "\n",
    "    between_x = np.arange(line_x_start, line_x_start + 3)\n",
    "    between_y = np.arange(bottom_line_y + 1, top_line_y)\n",
    "    between_x_values, between_y_values = zip(*itertools.product(between_x, between_y))\n",
    "\n",
    "#     above_x = np.arange(line_x_start, line_x_start + 3)\n",
    "    above_x = np.arange(line_x_end - 3, line_x_end)\n",
    "    above_y = np.arange(top_line_y + 1, top_line_y + 4)\n",
    "    above_x_values, above_y_values = zip(*itertools.product(above_x, above_y))\n",
    "    \n",
    "    below_x = np.arange(line_x_end - 3, line_x_end)\n",
    "    below_y = np.arange(bottom_line_y - 3, bottom_line_y)\n",
    "    below_x_values, below_y_values = zip(*itertools.product(below_x, below_y))\n",
    "\n",
    "    line_color = 0\n",
    "    between_colors = list(np.random.choice(np.arange(1, color_gen.n_types), len(between_x_values)))\n",
    "    above_below_colors = list(np.random.choice(np.arange(1, color_gen.n_types), len(above_x_values) + len(below_x_values)))\n",
    "    shape = 0\n",
    "    \n",
    "    x = np.array(list(range(line_x_start, line_x_end)) + \n",
    "                 list(range(line_x_start, line_x_end)) + \n",
    "                 list(between_x_values) + list(above_x_values) + list(below_x_values))\n",
    "    y = np.array([bottom_line_y] * line_length + \n",
    "                 [top_line_y] * line_length +\n",
    "                 list(between_y_values) + list(above_y_values) + list(below_y_values))\n",
    "    x_len = np.repeat(1, line_length * 2 + len(between_x_values) + len(above_x_values) + len(below_x_values))\n",
    "    y_len = np.repeat(1, line_length * 2 + len(between_y_values) + len(above_y_values) + len(below_y_values)) \n",
    "    color = to_one_hot(np.array([line_color] * line_length * 2 + \n",
    "                                between_colors + above_below_colors))\n",
    "    shape = to_one_hot(np.repeat(shape, line_length * 2 + len(between_y_values) + len(above_y_values) + len(below_y_values)))\n",
    "    \n",
    "    return combine(x, y, x_len, y_len, color, shape)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    visualize_objects(generate_3_6(gen_with_more_colors), gen_with_more_colors, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PER_LABEL = 4\n",
    "N_OBJECTS = 5\n",
    "FONTSIZE = 16\n",
    "\n",
    "descriptions = {\n",
    "    MultipleDAdjacentRelation: 'Are any two objects adjacent (L1 distance of 1)?',\n",
    "    ColorAboveColorRelation: 'Is there a blue object above (or at the same height of) all orange objects?',\n",
    "    ObjectCountRelation: 'Are there more blue objects than squares?',\n",
    "    IdenticalObjectsRelation: 'Are any two objects identical (in shape and color)?',\n",
    "    BetweenRelation: 'Is there an object of one color between two objects of the other color?'\n",
    "}\n",
    "\n",
    "X = {}\n",
    "y = {}\n",
    "\n",
    "for relation_class in (BetweenRelation, \n",
    "                       # MultipleDAdjacentRelation, ColorAboveColorRelation, ObjectCountRelation, \n",
    "#                        IdenticalObjectsRelation\n",
    "                      ):\n",
    "    fig = plt.figure(figsize=(4 * IMAGES_PER_LABEL + 1, 8))\n",
    "    display(Markdown(f'# {relation_class.__name__}'))\n",
    "    display(Markdown(descriptions[relation_class]))\n",
    "    \n",
    "    gen = object_gen.SmartBalancedBatchObjectGenerator(N_OBJECTS, run.FIELD_CONFIGURATIONS['default'], relation_class,\n",
    "                                                       object_dtype=torch.float, label_dtype=torch.long,\n",
    "                                                       max_recursion_depth=100\n",
    "                                                      )\n",
    "\n",
    "    X[relation_class], y[relation_class] = gen(1000)\n",
    "    y[relation_class] = y[relation_class].bool()\n",
    "    positive_indices = np.random.choice(torch.nonzero(y[relation_class]).squeeze(), size=4, replace=False)\n",
    "    negative_indices = np.random.choice(torch.nonzero(~y[relation_class]).squeeze(), size=4, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(positive_indices):\n",
    "        ax = plt.subplot(2, IMAGES_PER_LABEL, i + 1)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Positive Examples', fontsize=FONTSIZE)\n",
    "            \n",
    "        visualize_objects(X[relation_class][idx], gen, ax)\n",
    "        ax.set_title(idx)\n",
    "\n",
    "        \n",
    "    for i, idx in enumerate(negative_indices):\n",
    "        ax = plt.subplot(2, IMAGES_PER_LABEL, i + IMAGES_PER_LABEL + 1)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Negative Examples', fontsize=FONTSIZE)\n",
    "            \n",
    "        visualize_objects(X[relation_class][idx], gen, ax)\n",
    "        ax.set_title(idx)\n",
    "        \n",
    "    plt.show()\n",
    "    display(Markdown(f'------'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generation details\n",
    "\n",
    "* We generate a dataset of $M$ images, each with $N$ objects to be balanced with respect to a particular relation.\n",
    "* Each relation class (see the implementations in `object_relations.py`) knows how to convert a negative example to a positive, but not vice versa. That is, we can change a collections of objects where a relation doesn't hold to one where it does.\n",
    "* First, we sample $M$ images randomly. \n",
    "* If more than $M / 2$ are positive (with respect to the given relation), we resample all of the positive ones, repeating until at least $M / 2$ are negative.\n",
    "* We now have $M_{neg} > M / 2$ negative images. We convert $M_{neg} - M / 2$ of them to be positive, guaranteeing our dataset is balanced 50/50.\n",
    "* The logic above is implemented in the `SmartBalancedBatchObjectGenerator` class in `object_gen.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = object_gen.SmartBalancedBatchObjectGenerator(4, run.FIELD_CONFIGURATIONS['default'], BetweenRelation,\n",
    "                                                       object_dtype=torch.float, label_dtype=torch.long,\n",
    "                                                       max_recursion_depth=100)\n",
    "\n",
    "no_constraints_gen = object_gen.SmartBalancedBatchObjectGenerator(4, run.FIELD_CONFIGURATIONS['default'], BetweenRelation,\n",
    "                                                       object_dtype=torch.float, label_dtype=torch.long, constraints=[],\n",
    "                                                       max_recursion_depth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_POSITION_FIELDS = ('x', 'y')\n",
    "\n",
    "\n",
    "def current_no_position_collision_constraint(object_batch, relevant_indices, field_slices,\n",
    "                                     position_fields=DEFAULT_POSITION_FIELDS):\n",
    "    violating_indices = []\n",
    "\n",
    "    if relevant_indices is None:\n",
    "        relevant_indices = range(object_batch.shape[0])\n",
    "\n",
    "    for idx in relevant_indices:\n",
    "        object_positions = torch.cat([object_batch[idx, :, field_slices[pos]] for pos in position_fields],\n",
    "                                     dim=1).to(torch.float)\n",
    "\n",
    "        for obj_idx in range(object_positions.shape[0] - 1):\n",
    "            if (object_positions[obj_idx + 1:] == object_positions[obj_idx]).all(dim=1).any():\n",
    "                violating_indices.append(idx)\n",
    "                break\n",
    "\n",
    "    return violating_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = no_constraints_gen(1000)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[current_no_position_collision_constraint(X, None, no_constraints_gen.field_slices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_no_position_collision_constraint(object_batch, relevant_indices, field_slices,\n",
    "                                     position_fields=DEFAULT_POSITION_FIELDS):\n",
    "    violating_indices = []\n",
    "\n",
    "    if relevant_indices is None:\n",
    "        relevant_indices = range(object_batch.shape[0])\n",
    "\n",
    "    for idx in relevant_indices:\n",
    "        object_positions = torch.cat([object_batch[idx, :, field_slices[pos]] for pos in position_fields],\n",
    "                                     dim=1).to(torch.float).unsqueeze(0)\n",
    "#         print('P', object_positions)\n",
    "        for obj_idx in range(object_positions.shape[0] - 1):\n",
    "#             print(obj_idx, object_positions[obj_idx])\n",
    "#             print(object_positions[obj_idx + 1:])\n",
    "            if (object_positions[obj_idx + 1:] == object_positions[obj_idx]).any():\n",
    "                violating_indices.append(idx)\n",
    "                break\n",
    "                \n",
    "    return violating_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = previous_no_position_collision_constraint(X, [0, 1, 2], no_constraints_gen.field_slices)\n",
    "print(ind)\n",
    "X[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[ 3.,  8.,  0.,  1.,  0.,  1.],\n",
    "          [ 9.,  0.,  1.,  0.,  1.,  0.],\n",
    "          [ 5.,  4.,  1.,  0.,  1.,  0.],\n",
    "          [10., 12.,  0.,  1.,  1.,  0.]]).unsqueeze(0)\n",
    "previous_no_position_collision_constraint(t, None, no_constraints_gen.field_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[0, :, :2].unique(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_sets = ([], [previous_no_position_collision_constraint], [current_no_position_collision_constraint])\n",
    "names = ('None', 'Buggy', 'Fixed')\n",
    "N = 10000\n",
    "\n",
    "for n_obj in (5, 10):\n",
    "    print(f'With {n_obj} objects:')\n",
    "    for constraint_set, name in zip(constraint_sets, names):\n",
    "        gen = object_gen.SmartBalancedBatchObjectGenerator(n_obj, run.FIELD_CONFIGURATIONS['default'], \n",
    "                                                           MultipleDAdjacentRelation,\n",
    "                                                           object_dtype=torch.float, \n",
    "                                                           label_dtype=torch.long, \n",
    "                                                           constraints=constraint_set,\n",
    "                                                           max_recursion_depth=100)\n",
    "        X = gen(N)[0]\n",
    "        unique_counts = defaultdict(lambda: 0)\n",
    "        for b in range(X.shape[0]):\n",
    "            pos = X[b, :, :2]\n",
    "            unique_pos = set([tuple(x.numpy()) for x in pos])\n",
    "            unique_counts[len(unique_pos)] += 1\n",
    "\n",
    "        print(f'{name}: P(no collisions) = {unique_counts[n_obj] / N:.4f} [{unique_counts.items()}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = t.squeeze(0)\n",
    "objs[2, :2] = torch.tensor([3, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.relation.evaluate(objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
