{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../run'))\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from abc import abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvas\n",
    "import cv2\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.notebook import tqdm\n",
    "import tabulate\n",
    "\n",
    "from quinn_embedding_stimuli import *\n",
    "from quinn_embedding_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 33\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object generator and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = 20\n",
    "reference_size = (10, 100)\n",
    "reference_positions = [(105, 100)]\n",
    "\n",
    "target_patch = matplotlib.patches.Circle((0, 0), target_size // 2, color='blue')\n",
    "reference_patch = matplotlib.patches.Ellipse((0, 0), width=reference_size[1], \n",
    "                                             height=reference_size[0], color='green')\n",
    "\n",
    "blur_func = lambda x: cv2.blur(x, (5, 5))\n",
    "\n",
    "# gen = NaiveStimulusGenerator(target_size, refernce_size, target_color='black', dtype=torch.float32)\n",
    "gen = PatchStimulusGenerator(target_size, reference_size, target_patch, reference_patch,\n",
    "                             blur_func=blur_func)\n",
    "x = gen.generate((30, 30), reference_positions)\n",
    "plt.imshow(x.permute(1, 2, 0).numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "every = 5\n",
    "half_target = target_size // 2\n",
    "row_max = DEFAULT_CANVAS_SIZE[0] - half_target\n",
    "col_max = DEFAULT_CANVAS_SIZE[1] - half_target\n",
    "target_positions = [(r * every, c * every) for r, c \n",
    "                    in itertools.product(range(half_target // every, row_max // every), \n",
    "                                         range(half_target // every, col_max // every))]\n",
    "\n",
    "# batch = gen.batch_generate(target_positions, reference_positions)\n",
    "# batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniature_stimuli_every = 20\n",
    "row_max = DEFAULT_CANVAS_SIZE[0] - half_target\n",
    "col_max = DEFAULT_CANVAS_SIZE[1] - half_target\n",
    "miniature_target_positions = [(r * miniature_stimuli_every, c * miniature_stimuli_every) for r, c \n",
    "                                in itertools.product(range(1, \n",
    "                                                           row_max // miniature_stimuli_every + 1), \n",
    "                                                     range(1, \n",
    "                                                           col_max // miniature_stimuli_every + 1))]\n",
    "# miniature_target_positions\n",
    "# miniature_batch = gen.batch_generate(miniature_target_positions, reference_positions)\n",
    "# miniature_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AboveBelowEquilateralTripletGenerator:\n",
    "    def __init__(self, stimulus_generator, side_length_endpoints, \n",
    "                 vertical_margin=0, horizontal_margin=0,\n",
    "                 target_margin_from_reference_edge=0, pair_above=None,\n",
    "                 seed=RANDOM_SEED):\n",
    "        self.stimulus_generator = stimulus_generator\n",
    "        \n",
    "        if not hasattr(side_length_endpoints, '__len__'):\n",
    "            side_length_endpoints = (side_length_endpoints, side_length_endpoints)\n",
    "            \n",
    "        self.side_length_endpoints = side_length_endpoints\n",
    "            \n",
    "        self.vertical_margin = vertical_margin\n",
    "        self.horizontal_margin = horizontal_margin\n",
    "        \n",
    "        self.target_margin_from_reference_edge = target_margin_from_reference_edge\n",
    "        self.pair_above = pair_above\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.default_rng(self.seed)\n",
    "    \n",
    "    def __call__(self, n=1, normalize=True):\n",
    "        results = []\n",
    "        for _ in tqdm(range(n), desc='Data Generation'):\n",
    "            side_length = self.rng.integers(*self.side_length_endpoints)\n",
    "            height = (3 ** 0.5) * side_length / 2\n",
    "            half_height = height // 2\n",
    "            min_vertical_margin = height + (self.stimulus_generator.target_size[1] // 2)\n",
    "            \n",
    "            vertical_margin = max(min_vertical_margin, self.vertical_margin)\n",
    "            horizontal_margin = max(self.stimulus_generator.reference_size[1] // 2, self.horizontal_margin)\n",
    "            \n",
    "            reference_center_position = np.array(\n",
    "                (self.rng.integers(vertical_margin, self.stimulus_generator.canvas_size[0] - vertical_margin),\n",
    "                 self.rng.integers(horizontal_margin, self.stimulus_generator.canvas_size[1] - horizontal_margin)), \n",
    "                dtype=np.int)\n",
    "            \n",
    "            target_margin = (self.stimulus_generator.reference_size[1] - self.stimulus_generator.target_size[1]) // 2\n",
    "            left_target_horizontal_offset = self.rng.integers(-target_margin, target_margin - side_length)\n",
    "            middle_target_horizontal_offset = left_target_horizontal_offset + side_length // 2\n",
    "            right_target_horizontal_offset = left_target_horizontal_offset + side_length\n",
    "            \n",
    "            if self.pair_above is None:\n",
    "                pair_above = np.sign(self.rng.uniform(-0.5, 0.5))\n",
    "            else:\n",
    "                pair_above = self.pair_above and 1 or -1\n",
    "                \n",
    "            left_target_offset = np.array((pair_above * half_height, left_target_horizontal_offset), dtype=np.int)\n",
    "            middle_target_offset = np.array((-1 * pair_above * half_height, middle_target_horizontal_offset), dtype=np.int)\n",
    "            right_target_offset = np.array((pair_above * half_height, right_target_horizontal_offset), dtype=np.int)\n",
    "            \n",
    "            target_positions = [reference_center_position + offset for offset in \n",
    "                                (left_target_offset, right_target_offset, middle_target_offset)]\n",
    "            \n",
    "            results.append(self.stimulus_generator.batch_generate(target_positions, [reference_center_position], normalize=normalize))\n",
    "        \n",
    "        return torch.stack(results)\n",
    "    \n",
    "    \n",
    "class AboveBelowQuinnTripletGenerator:\n",
    "    def __init__(self, stimulus_generator, distance_endpoints, \n",
    "                 vertical_margin=0, horizontal_margin=0,\n",
    "                 target_margin_from_reference_edge=0, \n",
    "                 pair_above=None, two_objects_left=None,\n",
    "                 seed=RANDOM_SEED):\n",
    "        self.stimulus_generator = stimulus_generator\n",
    "        \n",
    "        if not hasattr(distance_endpoints, '__len__'):\n",
    "            distance_endpoints = (distance_endpoints, distance_endpoints)\n",
    "            \n",
    "        self.distance_endpoints = distance_endpoints\n",
    "            \n",
    "        self.vertical_margin = vertical_margin\n",
    "        self.horizontal_margin = horizontal_margin\n",
    "        \n",
    "        self.target_margin_from_reference_edge = target_margin_from_reference_edge\n",
    "        self.pair_above = pair_above\n",
    "        self.two_objects_left = two_objects_left\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.default_rng(self.seed)\n",
    "    \n",
    "    def __call__(self, n=1, normalize=True):\n",
    "        results = []\n",
    "        for _ in tqdm(range(n), desc='Data Generation'):\n",
    "            distance = self.rng.integers(*self.distance_endpoints)\n",
    "            half_distance = distance // 2\n",
    "            min_vertical_margin = distance + (self.stimulus_generator.target_size[1] // 2)\n",
    "            \n",
    "            vertical_margin = max(min_vertical_margin, self.vertical_margin)\n",
    "            horizontal_margin = max(self.stimulus_generator.reference_size[1] // 2, self.horizontal_margin)\n",
    "            \n",
    "            reference_center_position = np.array(\n",
    "                (self.rng.integers(vertical_margin, self.stimulus_generator.canvas_size[0] - vertical_margin),\n",
    "                 self.rng.integers(horizontal_margin, self.stimulus_generator.canvas_size[1] - horizontal_margin)), \n",
    "                dtype=np.int)\n",
    "            \n",
    "            target_margin = (self.stimulus_generator.reference_size[1] - self.stimulus_generator.target_size[1]) // 2\n",
    "            left_target_horizontal_offset = self.rng.integers(-target_margin, target_margin - distance)\n",
    "            right_target_horizontal_offset = left_target_horizontal_offset + distance\n",
    "            \n",
    "            if self.pair_above is None:\n",
    "                pair_above = np.sign(self.rng.uniform(-0.5, 0.5))\n",
    "            else:\n",
    "                pair_above = self.pair_above and 1 or -1\n",
    "            \n",
    "            two_objects_left = self.two_objects_left\n",
    "            if two_objects_left is None:\n",
    "                two_objects_left = self.rng.integers(0, 2)\n",
    "                \n",
    "            left_target_offset = np.array((pair_above * half_distance, left_target_horizontal_offset), dtype=np.int)\n",
    "            right_target_offset = np.array((pair_above * half_distance, right_target_horizontal_offset), dtype=np.int)\n",
    "            other_side_target_offset = np.array((-pair_above * half_distance, two_objects_left and left_target_horizontal_offset or right_target_horizontal_offset), dtype=np.int)\n",
    "            \n",
    "            target_positions = [reference_center_position + offset for offset in \n",
    "                                (left_target_offset, right_target_offset, other_side_target_offset)]\n",
    "            \n",
    "            results.append(self.stimulus_generator.batch_generate(target_positions, [reference_center_position], normalize=normalize))\n",
    "        \n",
    "        return torch.stack(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "\n",
    "above_below_equilateral_gen = AboveBelowEquilateralTripletGenerator(gen, (40, 80))\n",
    "results = above_below_equilateral_gen(N, normalize=False)\n",
    "\n",
    "plt.figure(figsize=(13, 5 * N))\n",
    "\n",
    "for row in range(N):\n",
    "    for col in range(3):\n",
    "        ax = plt.subplot(N, 3, (3 * row) + col + 1)\n",
    "        ax.imshow(results[row, col].permute(1, 2, 0).numpy())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "\n",
    "above_below_quinn_gen = AboveBelowQuinnTripletGenerator(gen, (30, 80))\n",
    "results = above_below_quinn_gen(N, normalize=False)\n",
    "\n",
    "plt.figure(figsize=(13, 5 * N))\n",
    "\n",
    "for row in range(N):\n",
    "    for col in range(3):\n",
    "        ax = plt.subplot(N, 3, (3 * row) + col + 1)\n",
    "        ax.imshow(results[row, col].permute(1, 2, 0).numpy())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self, name, correct_index=0):\n",
    "        self.name = name\n",
    "        self.correct_index = correct_index\n",
    "        \n",
    "    @abstractmethod\n",
    "    def __call__(self, pairwise_cosines):\n",
    "        pass\n",
    "    \n",
    "    def aggregate(self, result_list):\n",
    "        if isinstance(result_list[0], torch.Tensor):\n",
    "            return torch.cat(result_list).detach().cpu().numpy()\n",
    "        \n",
    "        if isinstance(result_list[0], np.ndarray):\n",
    "            return np.concatenate(result_list)\n",
    "        \n",
    "        raise ValueError(f'Can only combine lists of torch.Tensor or np.ndarray, received {type(result_list[0])}')\n",
    "\n",
    "        \n",
    "class AccuracyMetric(Metric):\n",
    "    def __init__(self, name, correct_index=0):\n",
    "        super(AccuracyMetric, self).__init__(name, correct_index)\n",
    "        \n",
    "    def __call__(self, pairwise_cosines):\n",
    "        return (pairwise_cosines.argmax(dim=1) == self.correct_index).to(torch.float)\n",
    "        \n",
    "        \n",
    "class DifferenceMetric(Metric):\n",
    "    def __init__(self, name, correct_index=0, combine_func=torch.mean,\n",
    "                 combine_func_kwargs=dict(dim=1)):\n",
    "        super(DifferenceMetric, self).__init__(name, correct_index)\n",
    "        self.combine_func = combine_func\n",
    "        self.incorrect_indices = list(range(3))\n",
    "        self.incorrect_indices.remove(correct_index)\n",
    "        self.combine_func_kwargs = combine_func_kwargs\n",
    "        \n",
    "    def __call__(self, pairwise_cosines):\n",
    "        return pairwise_cosines[:, self.correct_index] - self.combine_func(pairwise_cosines[:, self.incorrect_indices], **self.combine_func_kwargs)\n",
    "    \n",
    "    \n",
    "METRICS = (AccuracyMetric('Accuracy'), DifferenceMetric('MeanDiff'),\n",
    "           DifferenceMetric('MaxDiff', combine_func=lambda x: torch.max(x, dim=1).values, combine_func_kwargs={}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual task implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def quinn_embedding_task(triplet_generator, models, model_names, metrics=METRICS, \n",
    "                         N=1024, batch_size=BATCH_SIZE):\n",
    "    \n",
    "    data = triplet_generator(N)\n",
    "    dataloader = DataLoader(TensorDataset(data), batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    all_model_results = defaultdict(lambda: defaultdict(list))\n",
    "    cos = nn.CosineSimilarity(dim=-1)\n",
    "    triangle_indices = np.triu_indices(3, 1)\n",
    "    \n",
    "    for model, model_name in tqdm(zip(models, model_names), desc='Models'):\n",
    "        model.eval()\n",
    "        \n",
    "        for b in tqdm(dataloader, desc='Batches'):\n",
    "            x = b[0]  # shape (N, 3, 3, 224, 224)\n",
    "            x = x.view(-1, *x.shape[2:])\n",
    "            e = model(x.to(device)).detach()\n",
    "            e = e.view(N, 3, -1)  # shape (N, 3, Z)\n",
    "            \n",
    "            embedding_pairwise_cosine = cos(e[:, :, None, :], e[:, None, :, :])  # shape (N, 3, 3)\n",
    "            triplet_cosines = embedding_pairwise_cosine[:, triangle_indices[0], triangle_indices[1]] # shape (N, 3)\n",
    "            \n",
    "            for metric in metrics:\n",
    "                all_model_results[model_name][metric.name].append(metric(triplet_cosines))\n",
    "                \n",
    "        for metric in metrics:\n",
    "            all_model_results[model_name][metric.name] = metric.aggregate(all_model_results[model_name][metric.name])\n",
    "        \n",
    "    table_rows = [[model_name] + [f'{np.mean(all_model_results[model_name][metric.name]):.4f} \\\\pm {np.std(all_model_results[model_name][metric.name]) / (N ** 0.5):.4f}' \n",
    "                                 for metric in metrics]\n",
    "                 for model_name in model_names]\n",
    "    headers = ['Model'] + [metric.name for metric in metrics]\n",
    "    \n",
    "    display(Markdown(tabulate.tabulate(table_rows, headers, tablefmt=\"github\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saycam_mobilenet = build_model(MOBILENET, device, pretrained=False, saycam='SAY')\n",
    "imagenet_mobilenet = build_model(MOBILENET, device, pretrained=True)\n",
    "random_weights_mobilenet = build_model(MOBILENET, device, pretrained=False)\n",
    "\n",
    "saycam_resnext50_32x4d = build_model(RESNEXT, device, pretrained=False, saycam='SAY')\n",
    "imagenet_resnext50_32x4d = build_model(RESNEXT, device, pretrained=True)\n",
    "random_weights_resnext50_32x4d = build_model(RESNEXT, device, pretrained=False)\n",
    "\n",
    "vgg = build_model(VGG, device, pretrained=True)\n",
    "\n",
    "models = (saycam_mobilenet, imagenet_mobilenet, random_weights_mobilenet, r\n",
    "          saycam_resnext50_32x4d, imagenet_resnext50_32x4d, random_weights_resnext50_32x4d,\n",
    "          vgg)\n",
    "names = ('mobilenet-saycam', 'mobilenet-imagenet', 'mobilenet-random',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quinn_embedding_task(above_below_quinn_gen, models, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quinn_embedding_task(above_below_equilateral_gen, models, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(4, 3, 2)\n",
    "cos = nn.CosineSimilarity(dim=-1)\n",
    "triangle_indices = np.triu_indices(3, 1)\n",
    "\n",
    "embedding_pairwise_cosine = cos(t[:, :, None, :], t[:, None, :, :])\n",
    "print(embedding_pairwise_cosine.shape)\n",
    "print(embedding_pairwise_cosine)\n",
    "triplet_cosines = embedding_pairwise_cosine[:, triangle_indices[0], triangle_indices[1]] # shape (N, 3)\n",
    "triplet_cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[:, None, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[None, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[m(triplet_cosines) for m in METRICS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rainbow] *",
   "language": "python",
   "name": "conda-env-rainbow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
